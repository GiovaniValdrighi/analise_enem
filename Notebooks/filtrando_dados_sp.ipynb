{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "from tqdm import tqdm\n",
    "geolocator = Nominatim(user_agent='giovani_valdrighi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza de dados\n",
    "\n",
    "## Manténdo dados de São Paulo e colunas importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_iter = pd.read_csv(\"data/MICRODADOS_ENEM_2019.csv\", encoding = 'latin1', sep = \";\", chunksize = 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = 0\n",
    "chunks_filtered = []\n",
    "for chunk in chunk_iter:\n",
    "    total_rows += chunk.shape[0]\n",
    "    chunks_filtered.append(chunk[chunk['SG_UF_RESIDENCIA'] == 'SP'])\n",
    "df_sp = pd.concat(chunks_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas totais: 5095270\n",
      "Colunas totais: 136\n",
      "\n",
      "Mantendo apenas as linhas do estado de São Paulo\n",
      "Linhas restantes: 813772\n",
      "Removendo colunas que não serão usadas:\n",
      "Colunas com informações sobre cada questão do teste\n",
      "TX_RESPOSTAS_CN   TX_RESPOSTAS_CH   TX_RESPOSTAS_LC   TX_RESPOSTAS_MT  \n",
      "TX_GABARITO_CN   TX_GABARITO_CH   TX_GABARITO_LC   TX_GABARITO_MT\n",
      "Colunas com códigos que não serão úteis:\n",
      "CO_MUNICIPIO_NASCIMENTO  CO_UF_NASCIMENTO   CO_MUNICIPIO_ESC   CO_UF_ESC\n",
      "CO_PROVA_CN   CO_PROVA_CH CO_PROVA_LC  CO_PROVA_MT\n",
      "Colunas restantes: 120\n"
     ]
    }
   ],
   "source": [
    "print(f\"Linhas totais: {total_rows}\")\n",
    "print(f\"Colunas totais: {df_sp.shape[1]}\")\n",
    "print()\n",
    "print(\"Mantendo apenas as linhas do estado de São Paulo\")\n",
    "print(f\"Linhas restantes: {df_sp.shape[0]}\")\n",
    "print(\"Removendo colunas que não serão usadas:\")\n",
    "print(\"Colunas com informações sobre cada questão do teste\")\n",
    "print(\"TX_RESPOSTAS_CN   TX_RESPOSTAS_CH   TX_RESPOSTAS_LC   TX_RESPOSTAS_MT  \\nTX_GABARITO_CN   TX_GABARITO_CH   TX_GABARITO_LC   TX_GABARITO_MT\")\n",
    "df_sp = df_sp.drop(columns = ['TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH','TX_RESPOSTAS_LC','TX_RESPOSTAS_MT',\n",
    "                              'TX_GABARITO_CN','TX_GABARITO_CH','TX_GABARITO_LC','TX_GABARITO_MT'])\n",
    "print(\"Colunas com códigos que não serão úteis:\")\n",
    "print('CO_MUNICIPIO_NASCIMENTO  CO_UF_NASCIMENTO   CO_MUNICIPIO_ESC   CO_UF_ESC\\nCO_PROVA_CN   CO_PROVA_CH CO_PROVA_LC  CO_PROVA_MT')\n",
    "df_sp = df_sp.drop(columns = ['CO_MUNICIPIO_NASCIMENTO', 'CO_UF_NASCIMENTO', 'CO_MUNICIPIO_ESC',\n",
    "                              'CO_UF_ESC', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT'])\n",
    "print(f\"Colunas restantes: {df_sp.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.to_csv(\"data/MICRODADOS_ENEM_SP_2019.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza para modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only the rows where the student went to the test\n",
    "df = df_sp[(df_sp.TP_PRESENCA_CN == 1) & (df_sp.TP_PRESENCA_CH == 1) &\n",
    "       (df_sp.TP_PRESENCA_LC == 1) & (df_sp.TP_PRESENCA_MT == 1)]\n",
    "\n",
    "#removing presence columns\n",
    "df = df.drop(columns = ['TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT'])\n",
    "\n",
    "#creating NOTA column\n",
    "df['NOTA'] = 0.2 * (df.NU_NOTA_CN + df.NU_NOTA_CH + df.NU_NOTA_MT + df.NU_NOTA_LC + df.NU_NOTA_REDACAO)\n",
    "\n",
    "#removing other notes columns\n",
    "df = df.drop(columns = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_MT', 'NU_NOTA_LC',\n",
    "                        'NU_NOTA_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', \n",
    "                        'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5', 'TP_STATUS_REDACAO'])\n",
    "\n",
    "#removing columns that don't have relation with the result in the test\n",
    "df = df.drop(columns = ['NU_INSCRICAO', 'NU_ANO'])\n",
    "\n",
    "#removing columns with spatial information\n",
    "df = df.drop(columns = ['CO_MUNICIPIO_RESIDENCIA', 'NO_MUNICIPIO_RESIDENCIA', 'CO_UF_RESIDENCIA', 'SG_UF_RESIDENCIA',\n",
    "                        'NO_MUNICIPIO_NASCIMENTO', 'SG_UF_NASCIMENTO', 'CO_ESCOLA', 'NO_MUNICIPIO_ESC',\n",
    "                        'SG_UF_ESC', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_UF_PROVA', 'SG_UF_PROVA',])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming columns\n",
    "columns = ['NUM_IDADE', 'CAT_SEXO', 'CAT_ESTADO_CIVIL', 'CAT_COR_RACA',\n",
    "       'CAT_NACIONALIDADE', 'CAT_ST_CONCLUSAO', 'NUM_ANO_CONCLUIU', 'CAT_ESCOLA',\n",
    "       'CAT_ENSINO', 'CAT_TREINEIRO', 'CAT_DEPENDENCIA_ADM_ESC',\n",
    "       'CAT_LOCALIZACAO_ESC', 'CAT_SIT_FUNC_ESC', 'CAT_BAIXA_VISAO',\n",
    "       'CAT_CEGUEIRA', 'CAT_SURDEZ', 'CAT_DEFICIENCIA_AUDITIVA',\n",
    "       'CAT_SURDO_CEGUEIRA', 'CAT_DEFICIENCIA_FISICA', 'CAT_DEFICIENCIA_MENTAL',\n",
    "       'CAT_DEFICIT_ATENCAO', 'CAT_DISLEXIA', 'CAT_DISCALCULIA', 'CAT_AUTISMO',\n",
    "       'CAT_VISAO_MONOCULAR', 'CAT_OUTRA_DEF', 'CAT_GESTANTE', 'CAT_LACTANTE',\n",
    "       'CAT_IDOSO', 'CAT_ESTUDA_CLASSE_HOSPITALAR', 'CAT_SEM_RECURSO',\n",
    "       'CAT_BRAILLE', 'CAT_AMPLIADA_24', 'CAT_AMPLIADA_18', 'CAT_LEDOR',\n",
    "       'CAT_ACESSO', 'CAT_TRANSCRICAO', 'CAT_LIBRAS', 'CAT_TEMPO_ADICIONAL',\n",
    "       'CAT_LEITURA_LABIAL', 'CAT_MESA_CADEIRA_RODAS',\n",
    "       'CAT_MESA_CADEIRA_SEPARADA', 'CAT_APOIO_PERNA', 'CAT_GUIA_INTERPRETE',\n",
    "       'CAT_COMPUTADOR', 'CAT_CADEIRA_ESPECIAL', 'CAT_CADEIRA_CANHOTO',\n",
    "       'CAT_CADEIRA_ACOLCHOADA', 'CAT_PROVA_DEITADO', 'CAT_MOBILIARIO_OBESO',\n",
    "       'CAT_LAMINA_OVERLAY', 'CAT_PROTETOR_AURICULAR', 'CAT_MEDIDOR_GLICOSE',\n",
    "       'CAT_MAQUINA_BRAILE', 'CAT_SOROBAN', 'CAT_MARCA_PASSO', 'CAT_SONDA',\n",
    "       'CAT_MEDICAMENTOS', 'CAT_SALA_INDIVIDUAL', 'CAT_SALA_ESPECIAL',\n",
    "       'CAT_SALA_ACOMPANHANTE', 'CAT_MOBILIARIO_ESPECIFICO',\n",
    "       'CAT_MATERIAL_ESPECIFICO', 'CAT_NOME_SOCIAL', 'CAT_LINGUA', 'CAT_ESTUDO_PAI', 'CAT_ESTUDO_MAE',\n",
    "       'CAT_PROFISSAO_PAI', 'CAT_PROFISSAO_MAE', 'NUM_PESSOAS_RESIDENCIA', 'CAT_RENDA', \n",
    "       'NUM_EMPREGADO_DOMESTICO', 'NUM_BANHEIRO', 'NUM_QUARTOS', 'NUM_CARRO', 'NUM_MOTO', \n",
    "       'NUM_GELADEIRA', 'NUM_FREEZER', 'NUM_MAQUINA_LAVAR', 'NUM_MAQUINA_SECAR', \n",
    "       'NUM_MICRO_ONDAS', 'NUM_LAVAR_LOUCA', 'CAT_ASPIRADOR_PO', 'NUM_TV', 'CAT_DVD',\n",
    "       'CAT_TV_ASSINATURA', 'NUM_CELULAR', 'CAT_TELEFONE', 'NUM_COMPUTADOR', 'CAT_INTERNET', 'NUM_NOTA']\n",
    "df.columns = columns\n",
    "\n",
    "#changing values for columns\n",
    "df.NUM_EMPREGADO_DOMESTICO = df.NUM_EMPREGADO_DOMESTICO.map({'A': 0., 'B':1., 'C': 3., 'D':5.})\n",
    "for col in ['BANHEIRO', 'QUARTOS', 'CARRO', 'MOTO', 'GELADEIRA', 'FREEZER',\n",
    "           'MAQUINA_LAVAR', 'MAQUINA_SECAR', 'MICRO_ONDAS', 'LAVAR_LOUCA', \n",
    "            'TV', 'CELULAR', 'COMPUTADOR']:\n",
    "    df['NUM_'+col] = df['NUM_'+col].map({'A':0., 'B':1, 'C': 2, 'D':3, 'E':4})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaNs.\n",
      "NUM_IDADE                  0.000022\n",
      "CAT_ENSINO                 0.435017\n",
      "CAT_DEPENDENCIA_ADM_ESC    0.695623\n",
      "CAT_LOCALIZACAO_ESC        0.695623\n",
      "CAT_SIT_FUNC_ESC           0.695623\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Columns with NaNs.')\n",
    "print(df.loc[:, (df.isna().mean() > 0)].isna().mean())\n",
    "df.dropna().to_csv(\"data/ENEM_CLEAN.csv\", index = False)\n",
    "\n",
    "df = df.dropna(subset = ['NUM_IDADE'])\n",
    "#replacing nans\n",
    "for col in ['ENSINO', 'DEPENDENCIA_ADM_ESC',\n",
    "           'LOCALIZACAO_ESC', 'SIT_FUNC_ESC']:\n",
    "    df['CAT_'+col] = df['CAT_'+col].fillna(value = 'FALTANTE')\n",
    "\n",
    "df.to_csv('data/ENEM_CLEAN_WITH_NAN.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
