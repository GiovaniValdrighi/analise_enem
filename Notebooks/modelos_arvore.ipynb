{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wD-ZmJ14wtg"
   },
   "source": [
    "# Modelos de regressão com árvores\n",
    "\n",
    "Nesse Notebook iremos realizar o procedimento de afinamento dos hiper-parâmetros dos 3 modelos a serem considerados: árvores de decisão, árvores de decisão com boosting (CatBoost) e florestas aleatórias (Distributed Random Forests). As reespectivas bibliotecas utilizadas para esses modelos são Scikit-learn, CatBoost e H2O.\n",
    "\n",
    "Separando em dados de treino e teste, iremos realizar uma busca com valores possíveis para os parâmetros (_grid search_ ), realizando validação cruzada (_cross validation_ ) em cada uma das combinações possível. O melhor conjunto de hiper-parâmetros é então validado com o dado de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdAHHGo47Hew"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iF6HrDdj7zVh"
   },
   "outputs": [],
   "source": [
    "! apt-get install default-jre\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8v1KQ1U-STZ"
   },
   "outputs": [],
   "source": [
    "! pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRXo5-gi-j-f",
    "outputId": "475b267d-7f68-44fd-f633-a2c6cc1d3a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IlTxEgx94wth"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#training aux\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#models\n",
    "from sklearn import tree\n",
    "import h2o\n",
    "from catboost import CatBoostRegressor\n",
    "from h2o.estimators import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PXb4R_6b4wti"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/analise_enem/data/ENEM_CLEAN_WITH_NAN.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = df.loc[:, ~(df == 'FALTANTE').any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-u9ALpe4wti"
   },
   "source": [
    "## Modelos com árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJ8gyFmK4wtj",
    "outputId": "37b446be-20fa-4946-f3d1-401988323551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 25.\n"
     ]
    }
   ],
   "source": [
    "#models with numeric variables\n",
    "X = df[[col for col in df.columns if col[0:3] == 'NUM']].drop(columns = ['NUM_NOTA'])\n",
    "X_columns_names = X.columns\n",
    "X = X.values\n",
    "Y = df.NUM_NOTA.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "results_path = '/content/drive/MyDrive/analise_enem/results/decision_tree_numeric.csv'\n",
    "with open(results_path, \"w+\") as f:\n",
    "    f.write(\"max_depth;min_samples_split;min_samples_leaf;time;data;score\")\n",
    "\n",
    "i = 0\n",
    "for max_depth in [10, 15, 20]:\n",
    "    for min_samples_split in [20, 30, 40]:\n",
    "        for min_samples_leaf in [30, 45, 60]:\n",
    "            start = time.time()\n",
    "            model = tree.DecisionTreeRegressor(max_depth= max_depth,\n",
    "                                              min_samples_split = min_samples_split,\n",
    "                                              min_samples_leaf = min_samples_leaf)\n",
    "            \n",
    "            cv_scores = cross_val_score(model, x_train, y_train, cv = 3)\n",
    "            end = time.time()\n",
    "            with open(results_path, \"a\") as f:\n",
    "                f.write(f\"\\n{max_depth};{min_samples_split};{min_samples_leaf};{(end - start)/3:.4f};train;{cv_scores.mean()}\")\n",
    "            i+= 1\n",
    "            if i % 25 == 0:\n",
    "                print(f\"On iteration {i}.\")\n",
    "\n",
    "decision_tree_numeric_results = pd.read_csv(results_path, sep = \";\").sort_values('score', ascending = False)\n",
    "max_depth = decision_tree_numeric_results.max_depth.iloc[0]\n",
    "min_samples_split = decision_tree_numeric_results.min_samples_split.iloc[0]\n",
    "min_samples_leaf = decision_tree_numeric_results.min_samples_leaf.iloc[0]\n",
    "\n",
    "start = time.time()\n",
    "model = tree.DecisionTreeRegressor(max_depth= max_depth,\n",
    "                                              min_samples_split = min_samples_split,\n",
    "                                              min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "with open(results_path, \"a\") as f:\n",
    "    f.write(f\"\\n{max_depth};{min_samples_split};{min_samples_leaf};{end - start:.4f};test;{model.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFfwWP6C4wtk",
    "outputId": "181b6f55-b844-482a-f06b-fa0d285f8d28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 25.\n"
     ]
    }
   ],
   "source": [
    "#models with numeric variables and categorics\n",
    "X = pd.get_dummies(df, drop_first = True, columns = [col for col in df.columns if col[0:3] == 'CAT']).drop(columns = ['NUM_NOTA'])\n",
    "X_columns_names = X.columns\n",
    "X = X.values\n",
    "Y = df.NUM_NOTA.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "results_path = '/content/drive/MyDrive/analise_enem/results/decision_tree_numeric_categoric.csv'\n",
    "with open(results_path, \"w+\") as f:\n",
    "    f.write(\"max_depth;min_samples_split;min_samples_leaf;time;data;score\")\n",
    "\n",
    "i = 0\n",
    "for max_depth in [10, 15, 20]:\n",
    "    for min_samples_split in [20, 30, 40]:\n",
    "        for min_samples_leaf in [30, 45, 60]:\n",
    "            start = time.time()\n",
    "            model = tree.DecisionTreeRegressor(max_depth= max_depth,\n",
    "                                              min_samples_split = min_samples_split,\n",
    "                                              min_samples_leaf = min_samples_leaf,\n",
    "                                              )\n",
    "            \n",
    "            cv_scores = cross_val_score(model, x_train, y_train, cv = 3)\n",
    "            end = time.time()\n",
    "            with open(results_path, \"a\") as f:\n",
    "                f.write(f\"\\n{max_depth};{min_samples_split};{min_samples_leaf};{(end - start)/3:.4f};train;{cv_scores.mean()}\")\n",
    "            i+= 1\n",
    "            if i % 25 == 0:\n",
    "                print(f\"On iteration {i}.\")\n",
    "\n",
    "decision_tree_numeric_categoric_results = pd.read_csv(results_path, sep = \";\").sort_values('score', ascending = False)\n",
    "max_depth = decision_tree_numeric_categoric_results.max_depth.iloc[0]\n",
    "min_samples_split = decision_tree_numeric_categoric_results.min_samples_split.iloc[0]\n",
    "min_samples_leaf = decision_tree_numeric_categoric_results.min_samples_leaf.iloc[0]\n",
    "\n",
    "start = time.time()\n",
    "model = tree.DecisionTreeRegressor(max_depth= max_depth,\n",
    "                                    min_samples_split = min_samples_split,\n",
    "                                    min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "with open(results_path, \"a\") as f:\n",
    "    f.write(f\"\\n{max_depth};{min_samples_split};{min_samples_leaf};{end - start:.4f};test;{model.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qFUEC2EDduB"
   },
   "source": [
    "## Modelo CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5Kib_b-DcZF",
    "outputId": "57d9a43d-420c-4e3d-cfc0-a201fa09e6a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 5.\n",
      "On iteration 10.\n",
      "On iteration 15.\n",
      "On iteration 20.\n",
      "On iteration 25.\n"
     ]
    }
   ],
   "source": [
    "#models with numeric variables and categorics\n",
    "X = df.drop(columns = ['NUM_NOTA'])\n",
    "X_columns_names = X.columns\n",
    "#X = X.values\n",
    "Y = df.NUM_NOTA.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "results_path = '/content/drive/MyDrive/analise_enem/results/catboost_numeric_categoric.csv'\n",
    "with open(results_path, \"w+\") as f:\n",
    "    f.write(\"iterations;learning_rate;depth;time;data;score\")\n",
    "\n",
    "i = 0\n",
    "for iterations in [400, 500, 650]:\n",
    "    for learning_rate in [0.1, 0.2, 0.5]:\n",
    "        for depth in [6, 10, 14]:\n",
    "            start = time.time()\n",
    "            model = CatBoostRegressor(iterations = iterations,\n",
    "                                      learning_rate = learning_rate,\n",
    "                                      depth = depth,\n",
    "                                      verbose = False,\n",
    "                                      cat_features = [col for col in X_columns_names if col[0:3] == 'CAT'],\n",
    "                                      random_state = 1,\n",
    "                                      task_type='GPU'\n",
    "                                      )            \n",
    "            end = time.time()\n",
    "            cv_scores = cross_val_score(model, x_train, y_train, cv = 3)\n",
    "\n",
    "            with open(results_path, \"a\") as f:\n",
    "                f.write(f\"\\n{iterations};{learning_rate};{depth};{(end - start)/3:.4f};train;{cv_scores.mean()}\")\n",
    "            i+= 1\n",
    "            if i % 5 == 0:\n",
    "                print(f\"On iteration {i}.\")\n",
    "\n",
    "catboost_results = pd.read_csv(results_path, sep = \";\").sort_values('score', ascending = False)\n",
    "iterations = catboost_results.iterations.iloc[0]\n",
    "learning_rate = catboost_results.learning_rate.iloc[0]\n",
    "depth = catboost_results.depth.iloc[0]\n",
    "\n",
    "start = time.time()\n",
    "model = CatBoostRegressor(iterations = iterations,\n",
    "                               learning_rate = learning_rate,\n",
    "                               depth = depth,\n",
    "                               verbose = False,\n",
    "                               cat_features = [col for col in X_columns_names if col[0:3] == 'CAT'],\n",
    "                               random_state = 1,\n",
    "                               task_type='GPU'\n",
    "                              )            \n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "with open(results_path, \"a\") as f:\n",
    "    f.write(f\"\\n{iterations};{learning_rate};{depth};{end - start:.4f};test;{model.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_Yzpmd4Fpui"
   },
   "source": [
    "## Modelo Distributed Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "rtcyX0_7Or6p",
    "outputId": "ae718352-c2cf-46ec-a744-103d15e60c77"
   },
   "outputs": [],
   "source": [
    "h2o.init()\n",
    "\n",
    "h2o_df = h2o.H2OFrame(df)\n",
    "for col in h2o_df.columns:\n",
    "    if col[0:3] == 'CAT':\n",
    "        h2o_df[col] = h2o_df[col].asfactor()\n",
    "\n",
    "df_train, df_test = h2o_df.split_frame(ratios=[.8], seed=1)\n",
    "\n",
    "\n",
    "results_path = '/content/drive/MyDrive/analise_enem/results/drf_numeric_categoric.csv'\n",
    "#with open(results_path, \"w+\") as f:\n",
    "#    f.write(\"ntrees;max_depth;time;data;score\")\n",
    "\n",
    "\n",
    "i = 0\n",
    "for ntrees in []:#[25, 50, 75]:\n",
    "    for max_depth in []: #[5, 10, 15]:\n",
    "        start = time.time()\n",
    "        model = H2ORandomForestEstimator(\n",
    "                                        nfolds = 3,\n",
    "                                        ntrees = ntrees,\n",
    "                                        max_depth = max_depth,\n",
    "                                        seed = 1,\n",
    "                                        )            \n",
    "        model.train(x = [col for col in h2o_df.columns if col != 'NUM_NOTA'],\n",
    "                    y = 'NUM_NOTA',\n",
    "                    training_frame = df_train)\n",
    "        end = time.time()\n",
    "\n",
    "        with open(results_path, \"a\") as f:\n",
    "            f.write(f\"\\n{ntrees};{max_depth};{(end-start)/3:.4f};train;{model.r2()}\")\n",
    "        i+= 1\n",
    "        if i % 5 == 0:\n",
    "            print(f\"On iteration {i}.\")\n",
    "\n",
    "drf_results = pd.read_csv(results_path, sep = \";\").sort_values('score', ascending = False)\n",
    "ntrees = drf_results.ntrees.iloc[0]\n",
    "max_depth = drf_results.max_depth.iloc[0]\n",
    "\n",
    "start = time.time()\n",
    "model = H2ORandomForestEstimator(\n",
    "                                ntrees = int(ntrees),\n",
    "                                max_depth = int(max_depth),\n",
    "                                seed = 1\n",
    "                                )            \n",
    "model.train(x = [col for col in h2o_df.columns if col != 'NUM_NOTA'],\n",
    "            y = 'NUM_NOTA',\n",
    "            training_frame = df_train,\n",
    "            validation_frame = df_test)\n",
    "end = time.time()\n",
    "\n",
    "with open(results_path, \"a\") as f:\n",
    "    f.write(f\"\\n{ntrees};{max_depth};{end - start:.4f};test;{model.r2(valid = True)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "modelos_arvore.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
