{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "modelos_arvore.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wD-ZmJ14wtg"
      },
      "source": [
        "# Modelos de regressão com árvores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdAHHGo47Hew"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF6HrDdj7zVh"
      },
      "source": [
        "! apt-get install default-jre\n",
        "!java -version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8v1KQ1U-STZ"
      },
      "source": [
        "! pip install h2o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRXo5-gi-j-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475b267d-7f68-44fd-f633-a2c6cc1d3a25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlTxEgx94wth"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "#training aux\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#models\n",
        "from sklearn import tree\n",
        "import h2o\n",
        "from catboost import CatBoostRegressor\n",
        "from h2o.estimators import H2ORandomForestEstimator"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXb4R_6b4wti"
      },
      "source": [
        "#df = pd.read_csv('data/ENEM_CLEAN.csv')\n",
        "path = '/content/drive/MyDrive/analise_enem/data/ENEM_CLEAN_WITH_NAN.csv'\n",
        "df = pd.read_csv(path)\n",
        "df = df.loc[:, ~(df == 'FALTANTE').any()]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-u9ALpe4wti"
      },
      "source": [
        "## Modelos com árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ8gyFmK4wtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b446be-20fa-4946-f3d1-401988323551"
      },
      "source": [
        "#models with numeric variables\n",
        "X = df[[col for col in df.columns if col[0:3] == 'NUM']].drop(columns = ['NUM_NOTA'])\n",
        "X_columns_names = X.columns\n",
        "X = X.values\n",
        "Y = df.NUM_NOTA.values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "results_path = '/content/drive/MyDrive/analise_enem/results/decision_tree_numeric.csv'\n",
        "with open(results_path, \"w+\") as f:\n",
        "    f.write(\"max_depth;min_samples_split;min_samples_leaf;time;data;score\")\n",
        "\n",
        "i = 0\n",
        "for max_depth in [10, 15, 20]:\n",
        "    for min_samples_split in [20, 30, 40]:\n",
        "        for min_samples_leaf in [30, 45, 60]:\n",
        "            start = time.time()\n",
        "            model = tree.DecisionTreeRegressor(max_depth= max_depth,\n",
        "                                              min_samples_split = min_samples_split,\n",
        "                                              min_samples_leaf = min_samples_leaf)\n",
        "            \n",
        "            cv_scores = cross_val_score(model, x_train, y_train, cv = 3)\n",
        "            end = time.time()\n",
        "            with open(results_path, \"a\") as f:\n",
        "                f.write(f\"\\n{max_depth};{min_samples_split};{min_samples_leaf};{(end - start)/3:.4f};train;{cv_scores.mean()}\")\n",
        "            i+= 1\n",
        "            if i % 25 == 0:\n",
        "                print(f\"On iteration {i}.\")\n",
        "\n",
        "decision_tree_numeric_results = pd.read_csv(results_path, sep = \";\").sort_values('score', ascending = False)\n",
        "max_depth = decision_tree_numeric_results.max_depth.iloc[0]\n",
        "min_samples_split = decision_tree_numeric_results.min_samples_split.iloc[0]\n",
        "min_samples_leaf = decision_tree_numeric_results.min_samples_leaf.iloc[0]\n",
        "\n",
        "start = time.time()\n",
        "model = tree.DecisionTreeRegressor(max_depth= max_depth,\n",
        "                                              min_samples_split = min_samples_split,\n",
        "                                              min_samples_leaf = min_samples_leaf)\n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "end = time.time()\n",
        "\n",
        "with open(results_path, \"a\") as f:\n",
        "    f.write(f\"\\n{max_depth};{min_samples_split};{min_samples_leaf};{end - start:.4f};test;{model.score(x_test, y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On iteration 25.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFfwWP6C4wtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181b6f55-b844-482a-f06b-fa0d285f8d28"
      },
      "source": [
        "#models with numeric variables and categorics\n",
        "X = pd.get_dummies(df, drop_first = True, columns = [col for col in df.columns if col[0:3] == 'CAT']).drop(columns = ['NUM_NOTA'])\n",
        "X_columns_names = X.columns\n",
        "X = X.values\n",
        "Y = df.NUM_NOTA.values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "results_path = '/content/drive/MyDrive/analise_enem/results/decision_tree_numeric_categoric.csv'\n",
        "with open(results_path, \"w+\") as f:\n",
        "    f.write(\"max_depth;min_samples_split;min_samples_leaf;time;data;score\")\n",
        "\n",
        "i = 0\n",
        "for max_depth in [10, 15, 20]:\n",
        "    for min_samples_split in [20, 30, 40]:\n",
        "        for min_samples_leaf in [30, 45, 60]:\n",
        "            start = time.time()\n",
        "            model = tree.DecisionTreeRegressor(max_depth= max_depth,\n",
        "                                              min_samples_split = min_samples_split,\n",
        "                                              min_samples_leaf = min_samples_leaf,\n",
        "                                              )\n",
        "            \n",
        "            cv_scores = cross_val_score(model, x_train, y_train, cv = 3)\n",
        "            end = time.time()\n",
        "            with open(results_path, \"a\") as f:\n",
        "                f.write(f\"\\n{max_depth};{min_samples_split};{min_samples_leaf};{(end - start)/3:.4f};train;{cv_scores.mean()}\")\n",
        "            i+= 1\n",
        "            if i % 25 == 0:\n",
        "                print(f\"On iteration {i}.\")\n",
        "\n",
        "decision_tree_numeric_categoric_results = pd.read_csv(results_path, sep = \";\").sort_values('score', ascending = False)\n",
        "max_depth = decision_tree_numeric_categoric_results.max_depth.iloc[0]\n",
        "min_samples_split = decision_tree_numeric_categoric_results.min_samples_split.iloc[0]\n",
        "min_samples_leaf = decision_tree_numeric_categoric_results.min_samples_leaf.iloc[0]\n",
        "\n",
        "start = time.time()\n",
        "model = tree.DecisionTreeRegressor(max_depth= max_depth,\n",
        "                                    min_samples_split = min_samples_split,\n",
        "                                    min_samples_leaf = min_samples_leaf)\n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "end = time.time()\n",
        "\n",
        "with open(results_path, \"a\") as f:\n",
        "    f.write(f\"\\n{max_depth};{min_samples_split};{min_samples_leaf};{end - start:.4f};test;{model.score(x_test, y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On iteration 25.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qFUEC2EDduB"
      },
      "source": [
        "## Modelo CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Kib_b-DcZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d9a43d-420c-4e3d-cfc0-a201fa09e6a0"
      },
      "source": [
        "#models with numeric variables and categorics\n",
        "X = df.drop(columns = ['NUM_NOTA'])\n",
        "X_columns_names = X.columns\n",
        "#X = X.values\n",
        "Y = df.NUM_NOTA.values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "results_path = '/content/drive/MyDrive/analise_enem/results/catboost_numeric_categoric.csv'\n",
        "with open(results_path, \"w+\") as f:\n",
        "    f.write(\"iterations;learning_rate;depth;time;data;score\")\n",
        "\n",
        "i = 0\n",
        "for iterations in [400, 500, 650]:\n",
        "    for learning_rate in [0.1, 0.2, 0.5]:\n",
        "        for depth in [6, 10, 14]:\n",
        "            start = time.time()\n",
        "            model = CatBoostRegressor(iterations = iterations,\n",
        "                                      learning_rate = learning_rate,\n",
        "                                      depth = depth,\n",
        "                                      verbose = False,\n",
        "                                      cat_features = [col for col in X_columns_names if col[0:3] == 'CAT'],\n",
        "                                      random_state = 1,\n",
        "                                      task_type='GPU'\n",
        "                                      )            \n",
        "            end = time.time()\n",
        "            cv_scores = cross_val_score(model, x_train, y_train, cv = 3)\n",
        "\n",
        "            with open(results_path, \"a\") as f:\n",
        "                f.write(f\"\\n{iterations};{learning_rate};{depth};{(end - start)/3:.4f};train;{cv_scores.mean()}\")\n",
        "            i+= 1\n",
        "            if i % 5 == 0:\n",
        "                print(f\"On iteration {i}.\")\n",
        "\n",
        "catboost_results = pd.read_csv(results_path, sep = \";\").sort_values('score', ascending = False)\n",
        "iterations = catboost_results.iterations.iloc[0]\n",
        "learning_rate = catboost_results.learning_rate.iloc[0]\n",
        "depth = catboost_results.depth.iloc[0]\n",
        "\n",
        "start = time.time()\n",
        "model = CatBoostRegressor(iterations = iterations,\n",
        "                               learning_rate = learning_rate,\n",
        "                               depth = depth,\n",
        "                               verbose = False,\n",
        "                               cat_features = [col for col in X_columns_names if col[0:3] == 'CAT'],\n",
        "                               random_state = 1,\n",
        "                               task_type='GPU'\n",
        "                              )            \n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "end = time.time()\n",
        "\n",
        "with open(results_path, \"a\") as f:\n",
        "    f.write(f\"\\n{iterations};{learning_rate};{depth};{end - start:.4f};test;{model.score(x_test, y_test)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On iteration 5.\n",
            "On iteration 10.\n",
            "On iteration 15.\n",
            "On iteration 20.\n",
            "On iteration 25.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_Yzpmd4Fpui"
      },
      "source": [
        "## Modelo Distributed Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtcyX0_7Or6p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "ae718352-c2cf-46ec-a744-103d15e60c77"
      },
      "source": [
        "h2o.init()\n",
        "\n",
        "h2o_df = h2o.H2OFrame(df)\n",
        "for col in h2o_df.columns:\n",
        "    if col[0:3] == 'CAT':\n",
        "        h2o_df[col] = h2o_df[col].asfactor()\n",
        "\n",
        "df_train, df_test = h2o_df.split_frame(ratios=[.8], seed=1)\n",
        "\n",
        "\n",
        "results_path = '/content/drive/MyDrive/analise_enem/results/drf_numeric_categoric.csv'\n",
        "#with open(results_path, \"w+\") as f:\n",
        "#    f.write(\"ntrees;max_depth;time;data;score\")\n",
        "\n",
        "\n",
        "i = 0\n",
        "for ntrees in []:#[25, 50, 75]:\n",
        "    for max_depth in []: #[5, 10, 15]:\n",
        "        start = time.time()\n",
        "        model = H2ORandomForestEstimator(\n",
        "                                        nfolds = 3,\n",
        "                                        ntrees = ntrees,\n",
        "                                        max_depth = max_depth,\n",
        "                                        seed = 1,\n",
        "                                        )            \n",
        "        model.train(x = [col for col in h2o_df.columns if col != 'NUM_NOTA'],\n",
        "                    y = 'NUM_NOTA',\n",
        "                    training_frame = df_train)\n",
        "        end = time.time()\n",
        "\n",
        "        with open(results_path, \"a\") as f:\n",
        "            f.write(f\"\\n{ntrees};{max_depth};{(end-start)/3:.4f};train;{model.r2()}\")\n",
        "        i+= 1\n",
        "        if i % 5 == 0:\n",
        "            print(f\"On iteration {i}.\")\n",
        "\n",
        "drf_results = pd.read_csv(results_path, sep = \";\").sort_values('score', ascending = False)\n",
        "ntrees = drf_results.ntrees.iloc[0]\n",
        "max_depth = drf_results.max_depth.iloc[0]\n",
        "\n",
        "start = time.time()\n",
        "model = H2ORandomForestEstimator(\n",
        "                                ntrees = int(ntrees),\n",
        "                                max_depth = int(max_depth),\n",
        "                                seed = 1\n",
        "                                )            \n",
        "model.train(x = [col for col in h2o_df.columns if col != 'NUM_NOTA'],\n",
        "            y = 'NUM_NOTA',\n",
        "            training_frame = df_train,\n",
        "            validation_frame = df_test)\n",
        "end = time.time()\n",
        "\n",
        "with open(results_path, \"a\") as f:\n",
        "    f.write(f\"\\n{ntrees};{max_depth};{end - start:.4f};test;{model.r2(valid = True)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>1 hour 8 mins</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.32.1.3</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>1 month and 3 days </td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_jov5k0</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>2.197 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O_API_Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.7.10 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         1 hour 8 mins\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.32.1.3\n",
              "H2O_cluster_version_age:    1 month and 3 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_jov5k0\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    2.197 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
              "Python_version:             3.7.10 final\n",
              "--------------------------  ------------------------------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/h2o/estimators/estimator_base.py:200: RuntimeWarning: Dropping bad and constant columns: [CAT_CADEIRA_CANHOTO, CAT_PROVA_DEITADO, CAT_CADEIRA_ESPECIAL]\n",
            "  warnings.warn(mesg[\"message\"], RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvPcNIrtWErB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}